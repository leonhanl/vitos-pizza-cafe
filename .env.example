# AWS Bedrock Configuration (used for embeddings)
# AWS credentials can be provided via environment variables, AWS profile, or IAM roles
# For environment variables approach:
# AWS_ACCESS_KEY_ID=your_aws_access_key_id_here
# AWS_SECRET_ACCESS_KEY=your_aws_secret_access_key_here
# For AWS profile approach (recommended):
# AWS_PROFILE=your_aws_profile_name
AWS_REGION=us-west-2

# OPENAI Compatible API Configuration

# This is the LiteLLM virtual API key
# OPENAI_API_KEY=your_litellm_api_key_here
# OPENAI_BASE_URL="http://localhost:4000"
# LLM_MODEL=deepseek/deepseek-chat

# This is the DeepSeek OPENAI compatible API key
# OPENAI_API_KEY=your_deepseek_api_key_here
# OPENAI_BASE_URL="https://api.deepseek.com/v1"
# LLM_MODEL=deepseek-chat

# This is the OpenRouter OPENAI compatible API key
# OPENAI_API_KEY=your_openrouter_api_key_here
# OPENAI_BASE_URL="https://openrouter.ai/api/v1"
# LLM_MODEL="openai/gpt-5-mini"

# This is the real OPENAI_API_KEY, you don't need to specify the OPENAI_BASE_URL if you use the real OPENAI API
OPENAI_API_KEY=your_openai_api_key_here
# LLM_MODEL=gpt-5
# LLM_MODEL=gpt-5-mini
LLM_MODEL=gpt-5-nano


# X-Pan Configuration
X_PAN_TOKEN=your_xpan_token_here
X_PAN_AI_MODEL=gpt-5-mini
X_PAN_APP_NAME='Vitos Pizza Cafe'
X_PAN_APP_USER='Vitos-Admin'
X_PAN_INPUT_CHECK_PROFILE_NAME='Demo-Profile-for-Input'
X_PAN_OUTPUT_CHECK_PROFILE_NAME='Demo-Profile-for-Output'

# Amap Configuration
AMAP_API_KEY=your_amap_api_key_here

# LangSmith Configuration
LANGSMITH_TRACING=false
LANGSMITH_API_KEY=your_langsmith_api_key_here
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_PROJECT=vitos-pizza-cafe

# Logging Configuration
LOG_LEVEL=INFO

# Instructions:
# 1. Copy this file and rename it to .env
# 2. Replace all 'your_xxx_api_key_here' with actual API keys
# 3. Make sure not to commit the .env file to version control
# 4. Set LANGSMITH_TRACING to true to enable tracing, false to disable 