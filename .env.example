# ============================================================================
# Vito's Pizza Cafe - Environment Configuration
# ============================================================================
#
# SETUP INSTRUCTIONS:
# 1. Copy this file and rename it to .env
# 2. Replace all placeholder values (your_*_api_key_here) with actual API keys
# 3. Uncomment the configuration block for your chosen LLM provider
# 4. Ensure the .env file is never committed to version control
#
# ============================================================================


# ============================================================================
# LLM PROVIDER CONFIGURATION
# ============================================================================
# The application supports multiple LLM providers via OpenAI-compatible APIs.
# Uncomment ONE configuration block below based on your provider.
# ----------------------------------------------------------------------------

# Option 1: OpenAI (Default)
# ----------------------------------------------------------------------------
# Use official OpenAI API. No need to specify OPENAI_BASE_URL.
OPENAI_API_KEY=your_openai_api_key_here
LLM_MODEL=gpt-5-mini
# Available models: gpt-5, gpt-5-mini, gpt-5-nano

# Option 2: DeepSeek
# ----------------------------------------------------------------------------
# Use DeepSeek's OpenAI-compatible API endpoint.
# OPENAI_API_KEY=your_deepseek_api_key_here
# OPENAI_BASE_URL=https://api.deepseek.com/v1
# LLM_MODEL=deepseek-chat

# Option 3: LiteLLM Proxy
# ----------------------------------------------------------------------------
# Route requests through LiteLLM proxy for unified model access.
# See litellm/ directory for Docker Compose setup.
# OPENAI_API_KEY=your_litellm_api_key_here
# OPENAI_BASE_URL=http://localhost:4000
# LLM_MODEL=deepseek/deepseek-chat

# Option 4: OpenRouter
# ----------------------------------------------------------------------------
# Access multiple models through OpenRouter's unified API.
# OPENAI_API_KEY=your_openrouter_api_key_here
# OPENAI_BASE_URL=https://openrouter.ai/api/v1
# LLM_MODEL=openai/gpt-5-mini


# ============================================================================
# EMBEDDING MODEL CONFIGURATION
# ============================================================================
# Used for RAG (Retrieval-Augmented Generation) vector embeddings.
# Currently supports OpenAI and OpenRouter providers.
# ----------------------------------------------------------------------------

# Default: Use OpenAI embeddings with the same API key as LLM
# If OPENAI_EMBEDDING_API_KEY is not set, it defaults to OPENAI_API_KEY
EMBEDDING_MODEL=text-embedding-3-small
# Available OpenAI models: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002

# Optional: Use separate API credentials for embeddings
# ----------------------------------------------------------------------------
# Uncomment these lines to use different credentials or provider for embeddings.
# Example: Use DeepSeek for LLM but OpenAI for embeddings
# OPENAI_EMBEDDING_API_KEY=your_openai_api_key_here
# OPENAI_EMBEDDING_BASE_URL defaults to https://api.openai.com/v1 if not specified

# Optional: Use OpenRouter for embeddings
# ----------------------------------------------------------------------------
# OPENAI_EMBEDDING_API_KEY=your_openrouter_api_key_here
# OPENAI_EMBEDDING_BASE_URL=https://openrouter.ai/api/v1
# EMBEDDING_MODEL=openai/text-embedding-3-small


# ============================================================================
# PALO ALTO NETWORKS AI RUNTIME SECURITY (AIRS)
# ============================================================================
# Configuration for AI Runtime Security (X-Pan) integration.
# Provides input/output safety checks and security monitoring.
# ----------------------------------------------------------------------------
X_PAN_TOKEN=your_xpan_token_here
X_PAN_AI_MODEL=gpt-5-mini
X_PAN_APP_NAME='Vitos Pizza Cafe'
X_PAN_APP_USER='Vitos-Admin'
X_PAN_INPUT_CHECK_PROFILE_NAME='Demo-Profile-for-Input'
X_PAN_OUTPUT_CHECK_PROFILE_NAME='Demo-Profile-for-Output'


# ============================================================================
# OPTIONAL INTEGRATIONS
# ============================================================================

# AMAP Location Services (MCP Tools)
# ----------------------------------------------------------------------------
# Required only if using AMAP location-based features.
AMAP_API_KEY=your_amap_api_key_here

# LangSmith Tracing and Monitoring
# ----------------------------------------------------------------------------
# Enable LangSmith for conversation flow debugging and monitoring.
LANGSMITH_TRACING=false
LANGSMITH_API_KEY=your_langsmith_api_key_here
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_PROJECT=vitos-pizza-cafe


# ============================================================================
# APPLICATION SETTINGS
# ============================================================================

# Logging Configuration
# ----------------------------------------------------------------------------
# Available levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO