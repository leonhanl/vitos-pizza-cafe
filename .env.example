# OPENAI Compatible API Configuration

# This is the LiteLLM virtual API key
# OPENAI_API_KEY=your_litellm_api_key_here
# OPENAI_BASE_URL="http://localhost:4000"
# LLM_MODEL=deepseek/deepseek-chat

# This is the DeepSeek OPENAI compatible API key
# OPENAI_API_KEY=your_deepseek_api_key_here
# OPENAI_BASE_URL="https://api.deepseek.com/v1"
# LLM_MODEL=deepseek-chat

# This is the OpenRouter OPENAI compatible API key
# OPENAI_API_KEY=your_openrouter_api_key_here
# OPENAI_BASE_URL="https://openrouter.ai/api/v1"
# LLM_MODEL="openai/gpt-5-mini"

# This is the real OPENAI_API_KEY, you don't need to specify the OPENAI_BASE_URL if you use the real OPENAI API
OPENAI_API_KEY=your_openai_api_key_here
# LLM_MODEL=gpt-5
# LLM_MODEL=gpt-5-mini
LLM_MODEL=gpt-5-nano

# OpenAI Embedding Model Configuration (used for RAG vector embeddings)
EMBEDDING_MODEL=text-embedding-3-small

# Optional: Separate API credentials for embeddings (if different from LLM)
# If not specified, OPENAI_EMBEDDING_API_KEY defaults to OPENAI_API_KEY
# If not specified, OPENAI_EMBEDDING_BASE_URL defaults to https://api.openai.com/v1 (NOT to OPENAI_BASE_URL)
# This prevents errors when using LLM providers that don't support OpenAI embeddings
# OPENAI_EMBEDDING_API_KEY=your_separate_openai_api_key_here
# OPENAI_EMBEDDING_BASE_URL="https://some-other-endpoint.com/v1"  # Only set if not using OpenAI

# Example: Use DeepSeek for LLM and OpenAI for embeddings
# OPENAI_API_KEY=sk-deepseek-...                        # DeepSeek key for LLM
# OPENAI_BASE_URL="https://api.deepseek.com/v1"         # DeepSeek for LLM
# LLM_MODEL=deepseek-chat
# OPENAI_EMBEDDING_API_KEY=sk-proj-...                  # OpenAI key for embeddings
# OPENAI_EMBEDDING_BASE_URL not needed - defaults to OpenAI's endpoint

# X-Pan Configuration
X_PAN_TOKEN=your_xpan_token_here
X_PAN_AI_MODEL=gpt-5-mini
X_PAN_APP_NAME='Vitos Pizza Cafe'
X_PAN_APP_USER='Vitos-Admin'
X_PAN_INPUT_CHECK_PROFILE_NAME='Demo-Profile-for-Input'
X_PAN_OUTPUT_CHECK_PROFILE_NAME='Demo-Profile-for-Output'

# Amap Configuration
AMAP_API_KEY=your_amap_api_key_here

# LangSmith Configuration
LANGSMITH_TRACING=false
LANGSMITH_API_KEY=your_langsmith_api_key_here
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_PROJECT=vitos-pizza-cafe

# Logging Configuration
LOG_LEVEL=INFO

# Instructions:
# 1. Copy this file and rename it to .env
# 2. Replace all 'your_xxx_api_key_here' with actual API keys
# 3. Make sure not to commit the .env file to version control
# 4. Set LANGSMITH_TRACING to true to enable tracing, false to disable 